# -*- coding: utf-8 -*-
"""clean_text

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PpLxEo2G-cMwnE2Dxo09c8-KdWgw8rrM
"""

import re
import string
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer



def clean_text(text):
    """
    Cleans text input for deep learning model by removing html tags, special characters,
    numbers, stop words, and applying lemmatization.
    
    Parameters:
    text (str): Text input to clean.
    
    Returns:
    cleaned_text (str): Cleaned text output.
    """
    
    # Remove HTML tags
    text = re.sub(r'<[^>]+>', '', text)
    
    # Remove special characters and numbers
    text = re.sub(r'[^\w\s]', '', text)
    text = re.sub(r'\d+', '', text)
    
    # Tokenize text
    tokens = word_tokenize(text.lower())
    
    # Remove stop words
    stop_words = set(stopwords.words('english'))
    tokens = [token for token in tokens if token not in stop_words]
    
    # Apply lemmatization
    lemmatizer = WordNetLemmatizer()
    tokens = [lemmatizer.lemmatize(token) for token in tokens]
    
    # Join tokens back into cleaned text
    cleaned_text = ' '.join(tokens)
    
    return cleaned_text